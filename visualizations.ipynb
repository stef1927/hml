{
 "metadata": {
  "name": "visualizations",
  "signature": "sha256:c7dab2cbe252fcfd76ed2d2c40417e98e343e3c1af99ce1f9baf383375e08c08"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os,sys\n",
      "import random,string,math,csv\n",
      "import inspect\n",
      "import pandas\n",
      "import numpy as np\n",
      "import scipy as sci\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Visualizing and analyzing the data "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read the traing set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all = list(csv.reader(open(\"../data/training.csv\",\"rb\"), delimiter=','))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "header = np.array(all[0])\n",
      "data = np.array(all[1:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a sub sample of 1000 rows for viewing some sample data in Excel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_sub = data[np.random.choice(data.shape[0], 1000, replace=False)]\n",
      "np.savetxt(\"../data/training_sub_set.csv\", np.append([header], data_sub, axis=0), fmt='%s',delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform feature scaling (x - min) / (max - min) so that all features are between 0 and 1, missing values become -1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = np.array([float(row[-2]) for row in all[1:]])\n",
      "labels = np.array([map(lambda l: 1.0 if l == 's' else 0.0, row[-1]) for row in all[1:]]).flatten()\n",
      "\n",
      "print weights\n",
      "print labels\n",
      "\n",
      "xs_hdr = header[1:-2]\n",
      "xs = np.array([map(float, row[1:-2]) for row in all[1:]])\n",
      "(numPoints,numFeatures) = xs.shape\n",
      "\n",
      "xs[xs == -999.0] = np.nan\n",
      "\n",
      "xs_min = np.nanmin(xs,0)\n",
      "xs_max = np.nanmax(xs,0)\n",
      "\n",
      "xs = (xs - xs_min) / (xs_max - xs_min) \n",
      "xs[np.isnan(xs)] = -1\n",
      "print xs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.00265331  2.23358449  2.34738894 ...,  0.01863612  1.68161144\n",
        "  1.87747381]\n",
        "[ 1.  0.  0. ...,  1.  0.  0.]\n",
        "[[ 0.10940657  0.07485418  0.06812844 ...,  0.63777778  0.10614258\n",
        "   0.06948372]\n",
        " [ 0.1283984   0.09965294  0.07215518 ..., -1.         -1.          0.02829991]\n",
        " [-1.          0.23500634  0.08907077 ..., -1.         -1.          0.0270908 ]\n",
        " ..., \n",
        " [ 0.08149997  0.08770931  0.05175641 ..., -1.         -1.          0.02570782]\n",
        " [ 0.07261903  0.02805782  0.04652418 ..., -1.         -1.          0.        ]\n",
        " [-1.          0.10543202  0.04802751 ..., -1.         -1.          0.        ]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sIndexes = labels == 1.0\n",
      "bIndexes = labels == 0.0\n",
      "\n",
      "sumWeights = np.sum(weights)\n",
      "sumSWeights = np.sum(weights[sIndexes])\n",
      "sumBWeights = np.sum(weights[bIndexes])\n",
      "\n",
      "print sumWeights, sumSWeights + sumBWeights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "411691.83593 411691.83593\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create scatter plots of features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(numFeatures):\n",
      "    for j in range(numFeatures):\n",
      "        if i == j:\n",
      "            continue\n",
      "            \n",
      "        fig = plt.figure()\n",
      "        fig.suptitle(xs_hdr[i] + '_' + xs_hdr[j], fontsize=14, fontweight='bold')\n",
      "        vsPlot = fig.add_subplot(111)\n",
      "        #fig.subplots_adjust(top=0.85)\n",
      "\n",
      "        vsPlot.set_xlabel(xs_hdr[i])\n",
      "        vsPlot.set_ylabel(xs_hdr[j])\n",
      "\n",
      "        vsPlot.scatter(xs[bIndexes,i], xs[bIndexes,j], color='b', alpha=0.25)\n",
      "        vsPlot.scatter(xs[sIndexes,i], xs[sIndexes,j], color='r', alpha=0.25)\n",
      "\n",
      "        plt.savefig('../data/scatter/' + xs_hdr[i] + '___vs____' + xs_hdr[j] + '.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Perform a PCA (Principal Component Analysis)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Train with xgboost"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add path of xgboost python module\n",
      "sys.path.append(\"../xgboost/python\")\n",
      "\n",
      "import xgboost as xgb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xgmat = xgb.DMatrix(xs, label=labels, missing = -1, weight=weights )\n",
      "\n",
      "param = {}\n",
      "\n",
      "# use logistic regression loss, use raw prediction before logistic transformation\n",
      "# since we only need the rank\n",
      "param['objective'] = 'binary:logitraw'\n",
      "# scale weight of positive examples\n",
      "param['scale_pos_weight'] = sumBWeights/sumSWeights\n",
      "param['bst:eta'] = 0.1 \n",
      "param['bst:max_depth'] = 6\n",
      "param['eval_metric'] = 'auc'\n",
      "param['silent'] = 1\n",
      "param['nthread'] = 16\n",
      "\n",
      "# you can directly throw param in, though we want to watch multiple metrics here \n",
      "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
      "\n",
      "watchlist = [ (xgmat,'train') ]\n",
      "# boost 120 tres\n",
      "num_round = 120\n",
      "\n",
      "bst = xgb.train( plst, xgmat, num_round, watchlist );\n",
      "\n",
      "bst.save_model('higgs.model')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading data end, start to boost trees\n",
        "finish training"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Plot the learning errors (to be continued)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resultsText = list(csv.reader(open(\"results.dta\",\"rb\"), delimiter='\\t'))\n",
      "ts = [int(result[0]) for result in resultsText]\n",
      "trainErrors = np.array([float(result[5]) for result in resultsText])\n",
      "testErrors = np.array([float(result[11]) for result in resultsText])\n",
      "\n",
      "fig = plt.figure()\n",
      "fig.suptitle('MultiBoost learning curves', fontsize=14, fontweight='bold')\n",
      "ax = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "ax.set_xlabel('number of boosting iterations')\n",
      "ax.set_ylabel('balanced weighted error rate')\n",
      "\n",
      "ax.annotate('training error', xy=(0.9*len(ts), trainErrors[len(ts)-1]), \n",
      "            xytext=(0.6*len(ts), trainErrors[len(ts)-1]-0.05),\n",
      "            arrowprops=dict(facecolor='blue', shrink=0.05))\n",
      "ax.annotate('validation error', xy=(0.9*len(ts), testErrors[len(ts)-1]), \n",
      "            xytext=(0.6*len(ts), testErrors[len(ts)-1]+0.05),\n",
      "            arrowprops=dict(facecolor='red', shrink=0.05))\n",
      "\n",
      "ax.plot(ts,trainErrors,'b-')\n",
      "ax.plot(ts,testErrors,'r-')\n",
      "\n",
      "ax.axis([0, len(ts), 0.1, 0.3])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-55-ca2a9dea7971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresultsText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results.dta\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultsText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainErrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultsText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtestErrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultsText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optimizing the AMS on the held out validation set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Approximate Median Significance\n",
      "\\begin{equation*}\n",
      "\\text{AMS} = \\sqrt{ 2 \\left( (s + b + 10) \\ln \\left( 1 + \\frac{s}{b +\n",
      "    10} \\right) - s \\right) }\n",
      "\\end{equation*}\n",
      "<code>s</code> and <code>b</code> are the sum of signal and background weights, respectively, in the selection region."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AMS(s,b):\n",
      "    assert s >= 0\n",
      "    assert b >= 0\n",
      "    bReg = 10.\n",
      "    return math.sqrt(2 * ((s + b + bReg) * \n",
      "                          math.log(1 + s / (b + bReg)) - s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run \n",
      "\n",
      "<code>multiboost --configfile configScoresValidation.txt</code>\n",
      "\n",
      "using <a href=\"https://www.lri.fr/~kegl/HiggsML/MultiBoost/configScoresValidation.txt\">configScoresValidation.txt</a> to output the posterior scores <code>scoresValidation.txt</code> on the validation set. You can change the effective number of trees used for the validation score in\n",
      "\n",
      "<code>posteriors validation.arff shyp.xml scoresValidation.txt <b>numIterations</b></code>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading the scores on the validation set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "validationScoresText = list(csv.reader(open(\"scoresValidation.txt\",\"rb\"), delimiter=','))\n",
      "validationScores = np.array([float(score[0]) for score in validationScoresText])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sorting the indices in increasing order of the scores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tIIs = validationScores.argsort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Weights have to be normalized to the same sum as in the full set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wFactor = 1.* numPoints / numPointsValidation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initializing $s$ and $b$ to the full sum of weights, we start by having all points in the selection region. <code>amss</code> will contain AMSs after each point moved out of the selection region in the sorted validation set. <code>amsMax</code> will contain the best validation AMS, and <code>threshold</code> will be the smallest score among the selected points. We will do <code>len(tIIs)</code> iterations, which means that <code>amss[-1]</code> is the AMS when only the point with the highest score is selected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = np.sum(weightsValidation[sSelectorValidation])\n",
      "b = np.sum(weightsValidation[bSelectorValidation])\n",
      "amss = np.empty([len(tIIs)])\n",
      "amsMax = 0\n",
      "threshold = 0.0\n",
      "for tI in range(len(tIIs)):\n",
      "    # don't forget to renormalize the weights to the same sum \n",
      "    # as in the complete training set\n",
      "    amss[tI] = AMS(max(0,s * wFactor),max(0,b * wFactor))\n",
      "    # careful with small regions, they fluctuate a lot\n",
      "    if tI < 0.9 * len(tIIs) and amss[tI] > amsMax:\n",
      "        amsMax = amss[tI]\n",
      "        threshold = validationScores[tIIs[tI]]\n",
      "        #print tI,threshold\n",
      "    if sSelectorValidation[tIIs[tI]]:\n",
      "        s -= weightsValidation[tIIs[tI]]\n",
      "    else:\n",
      "        b -= weightsValidation[tIIs[tI]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the AMS vs the rank."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "fig.suptitle('MultiBoost AMS curves', fontsize=14, fontweight='bold')\n",
      "vsRank = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "vsRank.set_xlabel('rank')\n",
      "vsRank.set_ylabel('AMS')\n",
      "\n",
      "vsRank.plot(amss,'b-')\n",
      "\n",
      "vsRank.axis([0,len(amss), 0, 4])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the AMS vs the score."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "fig.suptitle('MultiBoost AMS curves', fontsize=14, fontweight='bold')\n",
      "vsScore = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "vsScore.set_xlabel('score')\n",
      "vsScore.set_ylabel('AMS')\n",
      "\n",
      "vsScore.plot(validationScores[tIIs],amss,'b-')\n",
      "\n",
      "vsScore.axis([validationScores[tIIs[0]],validationScores[tIIs[-1]] , 0, 4])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Constructing the submission file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reading the test file, slicing off the header row and the id column, and converting the data into arff."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testText = list(csv.reader(open(\"../data/test.csv\",\"rb\"), delimiter=','))\n",
      "testIds = np.array([int(row[0]) for row in testText[1:]])\n",
      "xsTest = np.array([map(float, row[1:]) for row in testText[1:]])\n",
      "weightsTest = np.repeat(1.0,len(testText)-1)\n",
      "labelsTest = np.repeat('s',len(testText)-1)\n",
      "DataToArff(xsTest,labelsTest,weightsTest,header,\"HiggsML_challenge_test\",\"test\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run \n",
      "\n",
      "<code>multiboost --configfile configScoresTest.txt</code>\n",
      "\n",
      "using <a href=\"https://www.lri.fr/~kegl/HiggsML/MultiBoost/configScoresTest.txt\">configScoresTest.txt</a> to output the posterior scores <code>scoresTest.txt</code> on the test set. You can change the effective number of tree used for the test score in\n",
      "\n",
      "<code>posteriors test.arff shyp.xml scoresTest.txt <b>numIterations</b></code>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reading the test scores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testScoresText = list(csv.reader(open(\"scoresTest.txt\", \"rb\"),delimiter=','))\n",
      "testScores = np.array([float(score[0]) for score in testScoresText])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computing the rank order."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testInversePermutation = testScores.argsort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testPermutation = list(testInversePermutation)\n",
      "for tI,tII in zip(range(len(testInversePermutation)),\n",
      "                  testInversePermutation):\n",
      "    testPermutation[tII] = tI"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computing the submission file with columns EventId, RankOrder, and Class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = np.array([[str(testIds[tI]),str(testPermutation[tI]+1),\n",
      "                       's' if testScores[tI] >= threshold else 'b'] \n",
      "            for tI in range(len(testIds))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = np.append([['EventId','RankOrder','Class']],\n",
      "                        submission, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saving the file that can be submitted to Kaggle."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt(\"submission.csv\",submission,fmt='%s',delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}