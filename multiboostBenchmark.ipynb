{
 "metadata": {
  "name": "multiboostBenchmark",
  "signature": "sha256:c7dab2cbe252fcfd76ed2d2c40417e98e343e3c1af99ce1f9baf383375e08c08"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Running the <a href=\"http://www.multiboost.org\">multiboost</a> benchmark on the Higgs boson machine learning challenge"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random,string,math,csv,pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Train/validation cut and converting into arff"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def DataToArff(xs,labels,weights,header,title,fileName):\n",
      "    outFile = open(fileName + \".arff\",\"w\")\n",
      "    outFile.write(\"@RELATION \" + title + \"\\n\\n\")\n",
      "    #header\n",
      "    for feature in header:\n",
      "        outFile.write(\"@ATTRIBUTE \" + feature + \n",
      "                      \" NUMERIC\\n\")\n",
      "    # multiboost requires \u00b11*weight in two columns\n",
      "    outFile.write(\"@ATTRIBUTE classSignal NUMERIC\\n\")\n",
      "    outFile.write(\"@ATTRIBUTE classBackground NUMERIC\\n\")\n",
      "    outFile.write(\"\\n@DATA\\n\")\n",
      "    for x,label,weight in zip(xs,labels,weights):\n",
      "        for xj in x:\n",
      "            outFile.write(str(xj) + \",\")\n",
      "        if label == 's':\n",
      "            outFile.write(str(weight) + \",\" + str(-weight) + \"\\n\")\n",
      "        else:\n",
      "            outFile.write(str(-weight) + \",\" + str(weight) + \"\\n\")\n",
      "    outFile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all = list(csv.reader(open(\"../data/training.csv\",\"rb\"), delimiter=','))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "header = np.array(all[0][1:-2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs = np.array([map(float, row[1:-2]) for row in all[1:]])\n",
      "(numPoints,numFeatures) = xs.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sSelector = np.array([row[-1] == 's' for row in all[1:]])\n",
      "bSelector = np.array([row[-1] == 'b' for row in all[1:]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = np.array([float(row[-2]) for row in all[1:]])\n",
      "labels = np.array([row[-1] for row in all[1:]])\n",
      "sumWeights = np.sum(weights)\n",
      "sumSWeights = np.sum(weights[sSelector])\n",
      "sumBWeights = np.sum(weights[bSelector])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save/load permutation if you want to use the same cut "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "randomPermutation = random.sample(range(len(xs)), len(xs))\n",
      "np.savetxt(\"randomPermutation.csv\",randomPermutation,fmt='%d',delimiter=',')\n",
      "#randomPermutation = np.array(map(int,np.array(list(csv.reader(open(\"randomPermutation.csv\",\"rb\"), delimiter=','))).flatten()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "90/10 training/validation cut"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numPointsTrain = int(numPoints*0.9)\n",
      "numPointsValidation = numPoints - numPointsTrain\n",
      "\n",
      "xsTrain = xs[randomPermutation[:numPointsTrain]]\n",
      "xsValidation = xs[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "sSelectorTrain = sSelector[randomPermutation[:numPointsTrain]]\n",
      "bSelectorTrain = bSelector[randomPermutation[:numPointsTrain]]\n",
      "sSelectorValidation = sSelector[randomPermutation[numPointsTrain:]]\n",
      "bSelectorValidation = bSelector[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "weightsTrain = weights[randomPermutation[:numPointsTrain]]\n",
      "weightsValidation = weights[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "labelsTrain = labels[randomPermutation[:numPointsTrain]]\n",
      "labelsValidation = labels[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "sumWeightsTrain = np.sum(weightsTrain)\n",
      "sumSWeightsTrain = np.sum(weightsTrain[sSelectorTrain])\n",
      "sumBWeightsTrain = np.sum(weightsTrain[bSelectorTrain])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DataToArff(xsTrain,labelsTrain,weightsTrain,header,\"HiggsML_challenge_train\",\"training\")\n",
      "DataToArff(xsValidation,labelsValidation,weightsValidation,header,\"HiggsML_challenge_validation\",\"validation\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Running multiboost training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download multiboost from <a href=\"http://www.multiboost.org/download\">here</a> then compile it (or use the precompiled images). Then run\n",
      "<br>\n",
      "<p>\n",
      "<code>multiboost --configfile config.txt</code>\n",
      "<p>\n",
      "using <a href=\"https://www.lri.fr/~kegl/HiggsML/MultiBoost/config.txt\">config.txt</a>. It trains AdaBoost with 3000 trees of three leaves (two inner nodes). You can change these hyperparameters in the config file:\n",
      "<p>\n",
      "<code>baselearnertype SingleStumpLearner <b>numInnerNodes</b></code>\n",
      "<br>\n",
      "<code>traintest training.arff validation.arff <b>numIterations</b></code>\n",
      "<p>\n",
      "Running till the full 3000 iterations will take hours, but you can continue executing this script after about a minute when the code starts to produce the model file <code>shyp.xml</code> and the table with the errors <code>results.dta</code>. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can plot the learning curves (balanced weighted error rate) any time with the following command."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resultsText = list(csv.reader(open(\"results.dta\",\"rb\"), delimiter='\\t'))\n",
      "ts = [int(result[0]) for result in resultsText]\n",
      "trainErrors = np.array([float(result[5]) for result in resultsText])\n",
      "testErrors = np.array([float(result[11]) for result in resultsText])\n",
      "\n",
      "fig = plt.figure()\n",
      "fig.suptitle('MultiBoost learning curves', fontsize=14, fontweight='bold')\n",
      "ax = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "ax.set_xlabel('number of boosting iterations')\n",
      "ax.set_ylabel('balanced weighted error rate')\n",
      "\n",
      "ax.annotate('training error', xy=(0.9*len(ts), trainErrors[len(ts)-1]), \n",
      "            xytext=(0.6*len(ts), trainErrors[len(ts)-1]-0.05),\n",
      "            arrowprops=dict(facecolor='blue', shrink=0.05))\n",
      "ax.annotate('validation error', xy=(0.9*len(ts), testErrors[len(ts)-1]), \n",
      "            xytext=(0.6*len(ts), testErrors[len(ts)-1]+0.05),\n",
      "            arrowprops=dict(facecolor='red', shrink=0.05))\n",
      "\n",
      "ax.plot(ts,trainErrors,'b-')\n",
      "ax.plot(ts,testErrors,'r-')\n",
      "\n",
      "ax.axis([0, len(ts), 0.1, 0.3])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-55-ca2a9dea7971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresultsText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results.dta\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultsText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainErrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultsText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtestErrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultsText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Optimizing the AMS on the held out validation set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Approximate Median Significance\n",
      "\\begin{equation*}\n",
      "\\text{AMS} = \\sqrt{ 2 \\left( (s + b + 10) \\ln \\left( 1 + \\frac{s}{b +\n",
      "    10} \\right) - s \\right) }\n",
      "\\end{equation*}\n",
      "<code>s</code> and <code>b</code> are the sum of signal and background weights, respectively, in the selection region."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AMS(s,b):\n",
      "    assert s >= 0\n",
      "    assert b >= 0\n",
      "    bReg = 10.\n",
      "    return math.sqrt(2 * ((s + b + bReg) * \n",
      "                          math.log(1 + s / (b + bReg)) - s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run \n",
      "\n",
      "<code>multiboost --configfile configScoresValidation.txt</code>\n",
      "\n",
      "using <a href=\"https://www.lri.fr/~kegl/HiggsML/MultiBoost/configScoresValidation.txt\">configScoresValidation.txt</a> to output the posterior scores <code>scoresValidation.txt</code> on the validation set. You can change the effective number of trees used for the validation score in\n",
      "\n",
      "<code>posteriors validation.arff shyp.xml scoresValidation.txt <b>numIterations</b></code>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading the scores on the validation set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "validationScoresText = list(csv.reader(open(\"scoresValidation.txt\",\"rb\"), delimiter=','))\n",
      "validationScores = np.array([float(score[0]) for score in validationScoresText])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sorting the indices in increasing order of the scores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tIIs = validationScores.argsort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Weights have to be normalized to the same sum as in the full set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wFactor = 1.* numPoints / numPointsValidation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initializing $s$ and $b$ to the full sum of weights, we start by having all points in the selection region. <code>amss</code> will contain AMSs after each point moved out of the selection region in the sorted validation set. <code>amsMax</code> will contain the best validation AMS, and <code>threshold</code> will be the smallest score among the selected points. We will do <code>len(tIIs)</code> iterations, which means that <code>amss[-1]</code> is the AMS when only the point with the highest score is selected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = np.sum(weightsValidation[sSelectorValidation])\n",
      "b = np.sum(weightsValidation[bSelectorValidation])\n",
      "amss = np.empty([len(tIIs)])\n",
      "amsMax = 0\n",
      "threshold = 0.0\n",
      "for tI in range(len(tIIs)):\n",
      "    # don't forget to renormalize the weights to the same sum \n",
      "    # as in the complete training set\n",
      "    amss[tI] = AMS(max(0,s * wFactor),max(0,b * wFactor))\n",
      "    # careful with small regions, they fluctuate a lot\n",
      "    if tI < 0.9 * len(tIIs) and amss[tI] > amsMax:\n",
      "        amsMax = amss[tI]\n",
      "        threshold = validationScores[tIIs[tI]]\n",
      "        #print tI,threshold\n",
      "    if sSelectorValidation[tIIs[tI]]:\n",
      "        s -= weightsValidation[tIIs[tI]]\n",
      "    else:\n",
      "        b -= weightsValidation[tIIs[tI]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the AMS vs the rank."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "fig.suptitle('MultiBoost AMS curves', fontsize=14, fontweight='bold')\n",
      "vsRank = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "vsRank.set_xlabel('rank')\n",
      "vsRank.set_ylabel('AMS')\n",
      "\n",
      "vsRank.plot(amss,'b-')\n",
      "\n",
      "vsRank.axis([0,len(amss), 0, 4])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the AMS vs the score."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "fig.suptitle('MultiBoost AMS curves', fontsize=14, fontweight='bold')\n",
      "vsScore = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "vsScore.set_xlabel('score')\n",
      "vsScore.set_ylabel('AMS')\n",
      "\n",
      "vsScore.plot(validationScores[tIIs],amss,'b-')\n",
      "\n",
      "vsScore.axis([validationScores[tIIs[0]],validationScores[tIIs[-1]] , 0, 4])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Constructing the submission file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reading the test file, slicing off the header row and the id column, and converting the data into arff."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testText = list(csv.reader(open(\"../data/test.csv\",\"rb\"), delimiter=','))\n",
      "testIds = np.array([int(row[0]) for row in testText[1:]])\n",
      "xsTest = np.array([map(float, row[1:]) for row in testText[1:]])\n",
      "weightsTest = np.repeat(1.0,len(testText)-1)\n",
      "labelsTest = np.repeat('s',len(testText)-1)\n",
      "DataToArff(xsTest,labelsTest,weightsTest,header,\"HiggsML_challenge_test\",\"test\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run \n",
      "\n",
      "<code>multiboost --configfile configScoresTest.txt</code>\n",
      "\n",
      "using <a href=\"https://www.lri.fr/~kegl/HiggsML/MultiBoost/configScoresTest.txt\">configScoresTest.txt</a> to output the posterior scores <code>scoresTest.txt</code> on the test set. You can change the effective number of tree used for the test score in\n",
      "\n",
      "<code>posteriors test.arff shyp.xml scoresTest.txt <b>numIterations</b></code>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reading the test scores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testScoresText = list(csv.reader(open(\"scoresTest.txt\", \"rb\"),delimiter=','))\n",
      "testScores = np.array([float(score[0]) for score in testScoresText])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computing the rank order."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testInversePermutation = testScores.argsort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testPermutation = list(testInversePermutation)\n",
      "for tI,tII in zip(range(len(testInversePermutation)),\n",
      "                  testInversePermutation):\n",
      "    testPermutation[tII] = tI"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computing the submission file with columns EventId, RankOrder, and Class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = np.array([[str(testIds[tI]),str(testPermutation[tI]+1),\n",
      "                       's' if testScores[tI] >= threshold else 'b'] \n",
      "            for tI in range(len(testIds))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = np.append([['EventId','RankOrder','Class']],\n",
      "                        submission, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saving the file that can be submitted to Kaggle."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt(\"submission.csv\",submission,fmt='%s',delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}