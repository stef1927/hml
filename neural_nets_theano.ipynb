{
 "metadata": {
  "name": "",
  "signature": "sha256:52da3d0df3d0f2a36ee31b92d3627052138285cfb78e5f66100ad317d05112b0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os,sys, time\n",
      "import random,string,math,csv\n",
      "import numpy as np\n",
      "import scipy as sci"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read the traing set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all = list(csv.reader(open(\"../data/training.csv\",\"rb\"), delimiter=','))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform feature scaling ((x - min) / (max - min)) * 1000 so that all features are between 0 and 1000, missing values become 0. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(inData, c1, c2):\n",
      "    ret = np.array([map(float, row[c1 : c2]) for row in inData])\n",
      "    ret[ret == -999.0] = np.nan\n",
      "\n",
      "    ret_min = np.nanmin(ret,0)\n",
      "    ret_max = np.nanmax(ret,0)\n",
      "\n",
      "    ret = ((ret - ret_min) / (ret_max - ret_min)) * 1000 \n",
      "    ret[np.isnan(ret)] = 0\n",
      "    return ret"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = np.array([float(row[-2]) for row in all[1:]])\n",
      "labels = np.array([map(lambda l: 1.0 if l == 's' else 0.0, row[-1]) for row in all[1:]]).flatten()\n",
      "\n",
      "xs = normalize(all[1:], 1, -2)\n",
      "(numPoints,numFeatures) = xs.shape\n",
      "\n",
      "#print xs.shape\n",
      "#print xs\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(250000, 30)\n",
        "[[ 109.40656747   74.85418252   68.12844466 ...,  637.77777778\n",
        "   106.14258434   69.48371926]\n",
        " [ 128.39840336   99.65293628   72.15518435 ...,    0.            0.\n",
        "    28.29990578]\n",
        " [   0.          235.00633989   89.07076727 ...,    0.            0.\n",
        "    27.09079589]\n",
        " ..., \n",
        " [  81.4999721    87.70930696   51.75641203 ...,    0.            0.\n",
        "    25.70781905]\n",
        " [  72.61902548   28.0578198    46.52418203 ...,    0.            0.            0.        ]\n",
        " [   0.          105.43201826   48.02750811 ...,    0.            0.            0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build training and validation sets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sIndexes = labels == 1.0\n",
      "bIndexes = labels == 0.0\n",
      "\n",
      "sumWeights = np.sum(weights)\n",
      "sumSWeights = np.sum(weights[sIndexes])\n",
      "sumBWeights = np.sum(weights[bIndexes])\n",
      "\n",
      "#print numPoints, sumWeights, sumSWeights, sumBWeights\n",
      "\n",
      "randomPermutation = random.sample(range(len(xs)), len(xs))\n",
      "#np.savetxt(\"randomPermutation.csv\",randomPermutation,fmt='%d',delimiter=',')\n",
      "#randomPermutation = np.array(map(int,np.array(list(csv.reader(open(\"randomPermutation.csv\",\"rb\"), delimiter=','))).flatten()))\n",
      "\n",
      "numPointsTrain = int(numPoints*0.9)\n",
      "numPointsValidation = numPoints - numPointsTrain\n",
      "\n",
      "xsTrain = xs[randomPermutation[:numPointsTrain]]\n",
      "xsValidation = xs[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "sSelectorTrain = sIndexes[randomPermutation[:numPointsTrain]]\n",
      "bSelectorTrain = bIndexes[randomPermutation[:numPointsTrain]]\n",
      "sSelectorValidation = sIndexes[randomPermutation[numPointsTrain:]]\n",
      "bSelectorValidation = bIndexes[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "weightsTrain = weights[randomPermutation[:numPointsTrain]]\n",
      "weightsValidation = weights[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "labelsTrain = labels[randomPermutation[:numPointsTrain]]\n",
      "labelsValidation = labels[randomPermutation[numPointsTrain:]]\n",
      "\n",
      "sumWeightsTrain = np.sum(weightsTrain)\n",
      "sumSWeightsTrain = np.sum(weightsTrain[sSelectorTrain])\n",
      "sumBWeightsTrain = np.sum(weightsTrain[bSelectorTrain])\n",
      "\n",
      "print numPointsTrain, sumWeightsTrain, sumSWeightsTrain, sumBWeightsTrain"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "225000 371216.456888 621.253151395 370595.203736\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform logistic regression using theano"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "import theano.tensor as T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression(object):\n",
      "    \n",
      "    def __init__(self, input, n_in, n_out):\n",
      "        \"\"\" Initialize the parameters of the logistic regression\n",
      "\n",
      "        :type input: theano.tensor.TensorType\n",
      "        :param input: symbolic variable that describes the input of the\n",
      "                      architecture (one minibatch)\n",
      "\n",
      "        :type n_in: int\n",
      "        :param n_in: number of input units, the dimension of the space in\n",
      "                     which the datapoints lie\n",
      "\n",
      "        :type n_out: int\n",
      "        :param n_out: number of output units, the dimension of the space in\n",
      "                      which the labels lie\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        # The weights W as a matrix of shape (n_in, n_out)\n",
      "        self.W = theano.shared(value=np.zeros((n_in, n_out),\n",
      "                            dtype=theano.config.floatX),\n",
      "                            name='W', borrow=True)\n",
      "        # The baises b as a vector of n_out elements\n",
      "        self.b = theano.shared(value=np.zeros((n_out,),\n",
      "                            dtype=theano.config.floatX),\n",
      "                            name='b', borrow=True)\n",
      "\n",
      "        # compute vector of class-membership probabilities in symbolic form\n",
      "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
      "        # self.p_y_given_x = T.nnet.sigmoid(T.dot(input, self.W) + self.b)\n",
      "\n",
      "        # compute prediction as class whose probability is maximal in symbolic form\n",
      "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
      "\n",
      "        # parameters of the model\n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "    #def sigmoid_cost(self, y):    \n",
      "    #    return -T.mean(y[T.arange(y.shape[0])] * T.log(self.p_y_given_x[T.arange(y.shape[0])]) +\n",
      "    #        (1 - y[T.arange(y.shape[0])]) * T.log(1 - self.p_y_given_x[T.arange(y.shape[0])]))\n",
      "    \n",
      "    def negative_log_likelihood(self, y):\n",
      "        # y.shape[0] is (symbolically) the number of rows in y, i.e.,\n",
      "        # number of examples (call it n) in the minibatch\n",
      "        # T.arange(y.shape[0]) is a symbolic vector which will contain\n",
      "        # [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of\n",
      "        # Log-Probabilities (call it LP) with one row per example and\n",
      "        # one column per class LP[T.arange(y.shape[0]),y] is a vector\n",
      "        # v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,\n",
      "        # LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is\n",
      "        # the mean (across minibatch examples) of the elements in v,\n",
      "        # i.e., the mean log-likelihood across the minibatch.\n",
      "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
      "\n",
      "    def errors(self, y):\n",
      "        # check if y has same dimension of y_pred\n",
      "        if y.ndim != self.y_pred.ndim:\n",
      "            raise TypeError('y should have the same shape as self.y_pred',\n",
      "                ('y', target.type, 'y_pred', self.y_pred.type))\n",
      "        # check if y is of the correct datatype\n",
      "        if y.dtype.startswith('int'):\n",
      "            # the T.neq operator returns a vector of 0s and 1s, where 1\n",
      "            # represents a mistake in prediction\n",
      "            return T.mean(T.neq(self.y_pred, y))\n",
      "        else:\n",
      "            raise NotImplementedError()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shared_dataset(data_x, data_y, borrow=True):\n",
      "        \"\"\" Function that loads the dataset into shared variables\n",
      "\n",
      "        The reason we store our dataset in shared variables is to allow\n",
      "        Theano to copy it into the GPU memory (when code is run on GPU).\n",
      "        Since copying data into the GPU is slow, copying a minibatch everytime\n",
      "        is needed (the default behaviour if the data is not in a shared\n",
      "        variable) would lead to a large decrease in performance.\n",
      "        \"\"\"\n",
      "        shared_x = theano.shared(np.asarray(data_x, dtype=theano.config.floatX), borrow=borrow)\n",
      "        shared_y = theano.shared(np.asarray(data_y, dtype=theano.config.floatX), borrow=borrow)\n",
      "        \n",
      "        # When storing data on the GPU it has to be stored as floats\n",
      "        # therefore we will store the labels as ``floatX`` as well\n",
      "        # (``shared_y`` does exactly that). But during our computations\n",
      "        # we need them as ints (we use labels as index, and if they are\n",
      "        # floats it doesn't make sense) therefore instead of returning\n",
      "        # ``shared_y`` we will have to cast it to int. This little hack\n",
      "        # lets ous get around this issue\n",
      "        return shared_x, T.cast(shared_y, 'int32')\n",
      "\n",
      "train_set_x, train_set_y = shared_dataset(xsTrain, labelsTrain)\n",
      "valid_set_x, valid_set_y = shared_dataset(xsValidation, labelsValidation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class HiddenLayer(object):\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None, activation=T.tanh):\n",
      "        \"\"\"\n",
      "        Typical hidden layer of a MLP: units are fully-connected and have\n",
      "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
      "        and the bias vector b is of shape (n_out,).\n",
      "\n",
      "        NOTE : The nonlinearity used here is tanh\n",
      "\n",
      "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
      "\n",
      "        :type rng: np.random.RandomState\n",
      "        :param rng: a random number generator used to initialize weights\n",
      "\n",
      "        :type input: theano.tensor.dmatrix\n",
      "        :param input: a symbolic tensor of shape (n_examples, n_in)\n",
      "\n",
      "        :type n_in: int\n",
      "        :param n_in: dimensionality of input\n",
      "\n",
      "        :type n_out: int\n",
      "        :param n_out: number of hidden units\n",
      "\n",
      "        :type activation: theano.Op or function\n",
      "        :param activation: Non linearity to be applied in the hidden\n",
      "                           layer\n",
      "        \"\"\"\n",
      "        self.input = input\n",
      "\n",
      "        # `W` is initialized with `W_values` which is uniformely sampled\n",
      "        # from sqrt(-6./(n_in+n_hidden)) and sqrt(6./(n_in+n_hidden))\n",
      "        # for tanh activation function\n",
      "        # the output of uniform if converted using asarray to dtype\n",
      "        # theano.config.floatX so that the code is runable on GPU\n",
      "        # Note : optimal initialization of weights is dependent on the\n",
      "        #        activation function used (among other things).\n",
      "        #        For example, results presented in [Xavier10] suggest that you\n",
      "        #        should use 4 times larger initial weights for sigmoid\n",
      "        #        compared to tanh\n",
      "        #        We have no info for other function, so we use the same as\n",
      "        #        tanh.\n",
      "        if W is None:\n",
      "            W_values = np.asarray(rng.uniform(\n",
      "                    low=-np.sqrt(6. / (n_in + n_out)),\n",
      "                    high=np.sqrt(6. / (n_in + n_out)),\n",
      "                    size=(n_in, n_out)), dtype=theano.config.floatX)\n",
      "            if activation == theano.tensor.nnet.sigmoid:\n",
      "                W_values *= 4\n",
      "\n",
      "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
      "\n",
      "        if b is None:\n",
      "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
      "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
      "\n",
      "        self.W = W\n",
      "        self.b = b\n",
      "\n",
      "        lin_output = T.dot(input, self.W) + self.b\n",
      "        self.output = (lin_output if activation is None\n",
      "                       else activation(lin_output))\n",
      "        # parameters of the model\n",
      "        self.params = [self.W, self.b]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MLP(object):\n",
      "    \"\"\"Multi-Layer Perceptron Class\n",
      "\n",
      "    A multilayer perceptron is a feedforward artificial neural network model\n",
      "    that has one layer or more of hidden units and nonlinear activations.\n",
      "    Intermediate layers usually have as activation function tanh or the\n",
      "    sigmoid function (defined here by a ``HiddenLayer`` class)  while the\n",
      "    top layer is a softamx layer (defined here by a ``LogisticRegression``\n",
      "    class).\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
      "        \"\"\"Initialize the parameters for the multilayer perceptron\n",
      "\n",
      "        :type rng: numpy.random.RandomState\n",
      "        :param rng: a random number generator used to initialize weights\n",
      "\n",
      "        :type input: theano.tensor.TensorType\n",
      "        :param input: symbolic variable that describes the input of the\n",
      "        architecture (one minibatch)\n",
      "\n",
      "        :type n_in: int\n",
      "        :param n_in: number of input units, the dimension of the space in\n",
      "        which the datapoints lie\n",
      "\n",
      "        :type n_hidden: int\n",
      "        :param n_hidden: number of hidden units\n",
      "\n",
      "        :type n_out: int\n",
      "        :param n_out: number of output units, the dimension of the space in\n",
      "        which the labels lie\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "        # Since we are dealing with a one hidden layer MLP, this will translate\n",
      "        # into a HiddenLayer with a tanh activation function connected to the\n",
      "        # LogisticRegression layer; the activation function can be replaced by\n",
      "        # sigmoid or any other nonlinear function\n",
      "        self.hiddenLayer = HiddenLayer(rng=rng, input=input,\n",
      "                                       n_in=n_in, n_out=n_hidden,\n",
      "                                       activation=T.tanh)\n",
      "\n",
      "        # The logistic regression layer gets as input the hidden units\n",
      "        # of the hidden layer\n",
      "        self.logRegressionLayer = LogisticRegression(\n",
      "            input=self.hiddenLayer.output,\n",
      "            n_in=n_hidden,\n",
      "            n_out=n_out)\n",
      "\n",
      "        # L1 norm ; one regularization option is to enforce L1 norm to\n",
      "        # be small\n",
      "        self.L1 = abs(self.hiddenLayer.W).sum() \\\n",
      "                + abs(self.logRegressionLayer.W).sum()\n",
      "\n",
      "        # square of L2 norm ; one regularization option is to enforce\n",
      "        # square of L2 norm to be small\n",
      "        self.L2_sqr = (self.hiddenLayer.W ** 2).sum() \\\n",
      "                    + (self.logRegressionLayer.W ** 2).sum()\n",
      "\n",
      "        # negative log likelihood of the MLP is given by the negative\n",
      "        # log likelihood of the output of the model, computed in the\n",
      "        # logistic regression layer\n",
      "        self.negative_log_likelihood = self.logRegressionLayer.negative_log_likelihood\n",
      "        # same holds for the function computing the number of errors\n",
      "        self.errors = self.logRegressionLayer.errors\n",
      "\n",
      "        # the parameters of the model are the parameters of the two layer it is\n",
      "        # made out of\n",
      "        self.params = self.hiddenLayer.params + self.logRegressionLayer.params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_mlp(learning_rate=0.01, L1_reg=0.00, L2_reg=0.0001, n_epochs=1000, batch_size=20, n_hidden=500):\n",
      "    \"\"\"\n",
      "    Demonstrate stochastic gradient descent optimization for a multilayer\n",
      "    perceptron\n",
      "\n",
      "    :type learning_rate: float\n",
      "    :param learning_rate: learning rate used (factor for the stochastic\n",
      "    gradient\n",
      "\n",
      "    :type L1_reg: float\n",
      "    :param L1_reg: L1-norm's weight when added to the cost (see\n",
      "    regularization)\n",
      "\n",
      "    :type L2_reg: float\n",
      "    :param L2_reg: L2-norm's weight when added to the cost (see\n",
      "    regularization)\n",
      "\n",
      "    :type n_epochs: int\n",
      "    :param n_epochs: maximal number of epochs to run the optimizer\n",
      "   \"\"\"\n",
      "\n",
      "    # compute number of minibatches for training, validation and testing\n",
      "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "    #n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size\n",
      "\n",
      "    ######################\n",
      "    # BUILD ACTUAL MODEL #\n",
      "    ######################\n",
      "    print('Building the model, num train batches %i, num valid batches %i' % \\\n",
      "        (n_train_batches, n_valid_batches));\n",
      "\n",
      "    # allocate symbolic variables for the data\n",
      "    index = T.lscalar()  # index to a [mini]batch\n",
      "    x = T.matrix('x')  # the data is presented as rasterized images\n",
      "    y = T.ivector('y')  # the labels are presented as 1D vector of\n",
      "                        # [int] labels\n",
      "\n",
      "    rng = np.random.RandomState(1234)\n",
      "\n",
      "    # construct the MLP class\n",
      "    classifier = MLP(rng=rng, input=x, n_in=numFeatures, n_hidden=n_hidden, n_out=2)\n",
      "\n",
      "    # the cost we minimize during training is the negative log likelihood of\n",
      "    # the model plus the regularization terms (L1 and L2); cost is expressed\n",
      "    # here symbolically\n",
      "    cost = classifier.negative_log_likelihood(y) \\\n",
      "         + L1_reg * classifier.L1 \\\n",
      "         + L2_reg * classifier.L2_sqr\n",
      "\n",
      "    # compiling a Theano function that computes the mistakes that are made\n",
      "    # by the model on a minibatch\n",
      "    train_error_model = theano.function(inputs=[index],\n",
      "            outputs=classifier.errors(y),\n",
      "            givens={\n",
      "                x: train_set_x[index * batch_size:(index + 1) * batch_size],\n",
      "                y: train_set_y[index * batch_size:(index + 1) * batch_size]})\n",
      "\n",
      "    validate_error_model = theano.function(inputs=[index],\n",
      "            outputs=classifier.errors(y),\n",
      "            givens={\n",
      "                x: valid_set_x[index * batch_size:(index + 1) * batch_size],\n",
      "                y: valid_set_y[index * batch_size:(index + 1) * batch_size]})\n",
      "\n",
      "    # compute the gradient of cost with respect to theta (sotred in params)\n",
      "    # the resulting gradients will be stored in a list gparams\n",
      "    gparams = []\n",
      "    for param in classifier.params:\n",
      "        gparam = T.grad(cost, param)\n",
      "        gparams.append(gparam)\n",
      "\n",
      "    # specify how to update the parameters of the model as a list of\n",
      "    # (variable, update expression) pairs\n",
      "    updates = []\n",
      "    # given two list the zip A = [a1, a2, a3, a4] and B = [b1, b2, b3, b4] of\n",
      "    # same length, zip generates a list C of same size, where each element\n",
      "    # is a pair formed from the two lists :\n",
      "    #    C = [(a1, b1), (a2, b2), (a3, b3), (a4, b4)]\n",
      "    for param, gparam in zip(classifier.params, gparams):\n",
      "        updates.append((param, param - learning_rate * gparam))\n",
      "\n",
      "    # compiling a Theano function `train_model` that returns the cost, but\n",
      "    # in the same time updates the parameter of the model based on the rules\n",
      "    # defined in `updates`\n",
      "    train_model = theano.function(inputs=[index], outputs=cost,\n",
      "            updates=updates,\n",
      "            givens={\n",
      "                x: train_set_x[index * batch_size:(index + 1) * batch_size],\n",
      "                y: train_set_y[index * batch_size:(index + 1) * batch_size]})\n",
      "\n",
      "    ###############\n",
      "    # TRAIN MODEL #\n",
      "    ###############\n",
      "    print '... training'\n",
      "\n",
      "    # early-stopping parameters\n",
      "    patience = 20000  # look as this many examples regardless\n",
      "    patience_increase = 2  # wait this much longer when a new best is found\n",
      "    improvement_threshold = 0.995  # a relative improvement of this much is considered significant\n",
      "    validation_frequency = min(n_train_batches, patience / 2)\n",
      "                                  # go through this many\n",
      "                                  # minibatche before checking the network\n",
      "                                  # on the validation set; in this case we\n",
      "                                  # check every epoch\n",
      "\n",
      "    best_params = None\n",
      "    best_train_loss = np.inf\n",
      "    best_validation_loss = np.inf\n",
      "    best_iter = 0\n",
      "    test_score = 0.\n",
      "    start_time = time.clock()\n",
      "\n",
      "    epoch = 0\n",
      "    done_looping = False\n",
      "    \n",
      "    errorsTrain = np.zeros((n_epochs+1))\n",
      "    errorsValidation = np.zeros((n_epochs+1))    \n",
      "\n",
      "    while (epoch < n_epochs) and (not done_looping):\n",
      "        epoch = epoch + 1\n",
      "        for minibatch_index in xrange(n_train_batches):\n",
      "\n",
      "            minibatch_avg_cost = train_model(minibatch_index)\n",
      "            # iteration number\n",
      "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
      "\n",
      "            if (iter + 1) % validation_frequency == 0:\n",
      "                # compute zero-one loss on validation set\n",
      "                validation_losses = [validate_error_model(i) for i in xrange(n_valid_batches)]\n",
      "                this_validation_loss = np.mean(validation_losses)\n",
      "\n",
      "                train_losses = [train_error_model(i) for i in xrange(n_train_batches)]\n",
      "                this_train_loss = np.mean(train_losses)\n",
      "                    \n",
      "                print('epoch %i, minibatch %i/%i, patience %i, iter %i, train error %f %%, valid error %f %%, best valid error %f %%' %\n",
      "                     (epoch, minibatch_index + 1, n_train_batches, patience, iter, \n",
      "                      this_train_loss * 100., this_validation_loss * 100., best_validation_loss * 100.))\n",
      "\n",
      "                # if we got the best validation score until now\n",
      "                if this_validation_loss < best_validation_loss:\n",
      "                    #improve patience if loss improvement is good enough\n",
      "                    if this_validation_loss < best_validation_loss *  \\\n",
      "                           improvement_threshold:\n",
      "                        patience = max(patience, iter * patience_increase)\n",
      "\n",
      "                    best_validation_loss = this_validation_loss\n",
      "                    best_train_loss = this_train_loss\n",
      "                    best_iter = iter\n",
      "\n",
      "                    # TODO - calculate AMS of validation\n",
      "                      \n",
      "\n",
      "            if patience <= iter:\n",
      "                    done_looping = True\n",
      "                    break\n",
      "                    \n",
      "        errorsTrain[epoch] = best_train_loss\n",
      "        errorsValidation[epoch] = best_validation_loss\n",
      "        \n",
      "    end_time = time.clock()\n",
      "    print(('Optimization complete. Best validation score of %f %% '\n",
      "           'obtained at iteration %i, with test performance %f %%') %\n",
      "          (best_validation_loss * 100., best_iter + 1, test_score * 100.))\n",
      "    print >> sys.stderr, ('The code ran for %.2fm' % ((end_time - start_time) / 60.))\n",
      "    \n",
      "    return (classifier, epoch, errorsTrain, errorsValidation);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier, epoch, errorsTrain, errorsValidation = test_mlp(learning_rate=0.001, L1_reg=0.00, L2_reg=0.0001, n_epochs=1000, batch_size=50, n_hidden=100)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building the model, num train batches 4500, num valid batches 500\n",
        "... training"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 1, minibatch 4500/4500, patience 20000, iter 4499, train error 30.373778 %, valid error 31.036000 %, best valid error inf %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 2, minibatch 4500/4500, patience 20000, iter 8999, train error 29.026222 %, valid error 29.668000 %, best valid error 31.036000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 3, minibatch 4500/4500, patience 20000, iter 13499, train error 27.992444 %, valid error 28.492000 %, best valid error 29.668000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 4, minibatch 4500/4500, patience 26998, iter 17999, train error 27.492444 %, valid error 27.916000 %, best valid error 28.492000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 5, minibatch 4500/4500, patience 35998, iter 22499, train error 27.225778 %, valid error 27.824000 %, best valid error 27.916000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 6, minibatch 4500/4500, patience 35998, iter 26999, train error 26.934222 %, valid error 27.556000 %, best valid error 27.824000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 7, minibatch 4500/4500, patience 53998, iter 31499, train error 26.683111 %, valid error 27.088000 %, best valid error 27.556000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 8, minibatch 4500/4500, patience 62998, iter 35999, train error 27.192889 %, valid error 27.484000 %, best valid error 27.088000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 9, minibatch 4500/4500, patience 62998, iter 40499, train error 25.997778 %, valid error 26.516000 %, best valid error 27.088000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 10, minibatch 4500/4500, patience 80998, iter 44999, train error 25.690667 %, valid error 26.176000 %, best valid error 26.516000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 11, minibatch 4500/4500, patience 89998, iter 49499, train error 25.808889 %, valid error 26.564000 %, best valid error 26.176000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 12, minibatch 4500/4500, patience 89998, iter 53999, train error 25.359111 %, valid error 25.916000 %, best valid error 26.176000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 13, minibatch 4500/4500, patience 107998, iter 58499, train error 25.738222 %, valid error 26.256000 %, best valid error 25.916000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 14, minibatch 4500/4500, patience 107998, iter 62999, train error 25.736444 %, valid error 26.100000 %, best valid error 25.916000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 15, minibatch 4500/4500, patience 107998, iter 67499, train error 25.539556 %, valid error 25.684000 %, best valid error 25.916000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 16, minibatch 4500/4500, patience 134998, iter 71999, train error 25.432444 %, valid error 26.056000 %, best valid error 25.684000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 17, minibatch 4500/4500, patience 134998, iter 76499, train error 25.813778 %, valid error 26.452000 %, best valid error 25.684000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 18, minibatch 4500/4500, patience 134998, iter 80999, train error 25.464000 %, valid error 26.248000 %, best valid error 25.684000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 19, minibatch 4500/4500, patience 134998, iter 85499, train error 25.274222 %, valid error 25.976000 %, best valid error 25.684000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 20, minibatch 4500/4500, patience 134998, iter 89999, train error 25.533778 %, valid error 25.980000 %, best valid error 25.684000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 21, minibatch 4500/4500, patience 134998, iter 94499, train error 25.120889 %, valid error 25.652000 %, best valid error 25.684000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 22, minibatch 4500/4500, patience 134998, iter 98999, train error 24.923556 %, valid error 25.336000 %, best valid error 25.652000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 23, minibatch 4500/4500, patience 197998, iter 103499, train error 24.712444 %, valid error 25.084000 %, best valid error 25.336000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 24, minibatch 4500/4500, patience 206998, iter 107999, train error 24.789333 %, valid error 25.000000 %, best valid error 25.084000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 25, minibatch 4500/4500, patience 206998, iter 112499, train error 24.150667 %, valid error 24.736000 %, best valid error 25.000000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 26, minibatch 4500/4500, patience 224998, iter 116999, train error 24.261778 %, valid error 24.488000 %, best valid error 24.736000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 27, minibatch 4500/4500, patience 233998, iter 121499, train error 23.778222 %, valid error 24.092000 %, best valid error 24.488000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 28, minibatch 4500/4500, patience 242998, iter 125999, train error 23.892889 %, valid error 24.432000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 29, minibatch 4500/4500, patience 242998, iter 130499, train error 24.078222 %, valid error 24.312000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 30, minibatch 4500/4500, patience 242998, iter 134999, train error 23.950222 %, valid error 24.292000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 31, minibatch 4500/4500, patience 242998, iter 139499, train error 23.872889 %, valid error 24.384000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 32, minibatch 4500/4500, patience 242998, iter 143999, train error 25.338222 %, valid error 26.076000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 33, minibatch 4500/4500, patience 242998, iter 148499, train error 24.328444 %, valid error 25.172000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 34, minibatch 4500/4500, patience 242998, iter 152999, train error 24.518222 %, valid error 24.824000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 35, minibatch 4500/4500, patience 242998, iter 157499, train error 25.062667 %, valid error 25.340000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 36, minibatch 4500/4500, patience 242998, iter 161999, train error 24.569333 %, valid error 24.876000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 37, minibatch 4500/4500, patience 242998, iter 166499, train error 24.836889 %, valid error 25.372000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 38, minibatch 4500/4500, patience 242998, iter 170999, train error 23.882222 %, valid error 24.360000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 39, minibatch 4500/4500, patience 242998, iter 175499, train error 24.179111 %, valid error 24.632000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 40, minibatch 4500/4500, patience 242998, iter 179999, train error 23.603556 %, valid error 23.880000 %, best valid error 24.092000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 41, minibatch 4500/4500, patience 359998, iter 184499, train error 24.419111 %, valid error 24.568000 %, best valid error 23.880000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 42, minibatch 4500/4500, patience 359998, iter 188999, train error 24.080444 %, valid error 24.388000 %, best valid error 23.880000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 43, minibatch 4500/4500, patience 359998, iter 193499, train error 23.660000 %, valid error 23.852000 %, best valid error 23.880000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 44, minibatch 4500/4500, patience 359998, iter 197999, train error 24.030667 %, valid error 24.700000 %, best valid error 23.852000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 45, minibatch 4500/4500, patience 359998, iter 202499, train error 23.732444 %, valid error 24.160000 %, best valid error 23.852000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 46, minibatch 4500/4500, patience 359998, iter 206999, train error 23.268889 %, valid error 23.900000 %, best valid error 23.852000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 47, minibatch 4500/4500, patience 359998, iter 211499, train error 23.415556 %, valid error 23.900000 %, best valid error 23.852000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 48, minibatch 4500/4500, patience 359998, iter 215999, train error 23.191111 %, valid error 23.428000 %, best valid error 23.852000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 49, minibatch 4500/4500, patience 431998, iter 220499, train error 23.289333 %, valid error 23.724000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 50, minibatch 4500/4500, patience 431998, iter 224999, train error 24.420889 %, valid error 24.552000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 51, minibatch 4500/4500, patience 431998, iter 229499, train error 24.416000 %, valid error 24.864000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 52, minibatch 4500/4500, patience 431998, iter 233999, train error 24.050667 %, valid error 24.536000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 53, minibatch 4500/4500, patience 431998, iter 238499, train error 24.740444 %, valid error 25.360000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 54, minibatch 4500/4500, patience 431998, iter 242999, train error 23.928889 %, valid error 24.088000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 55, minibatch 4500/4500, patience 431998, iter 247499, train error 24.192000 %, valid error 24.384000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 56, minibatch 4500/4500, patience 431998, iter 251999, train error 24.117778 %, valid error 24.524000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 57, minibatch 4500/4500, patience 431998, iter 256499, train error 24.208889 %, valid error 24.856000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 58, minibatch 4500/4500, patience 431998, iter 260999, train error 23.824889 %, valid error 24.208000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 59, minibatch 4500/4500, patience 431998, iter 265499, train error 25.082222 %, valid error 25.516000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 60, minibatch 4500/4500, patience 431998, iter 269999, train error 23.715556 %, valid error 24.288000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 61, minibatch 4500/4500, patience 431998, iter 274499, train error 23.418222 %, valid error 23.948000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 62, minibatch 4500/4500, patience 431998, iter 278999, train error 23.384889 %, valid error 23.748000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 63, minibatch 4500/4500, patience 431998, iter 283499, train error 24.244889 %, valid error 24.516000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 64, minibatch 4500/4500, patience 431998, iter 287999, train error 23.672889 %, valid error 23.976000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 65, minibatch 4500/4500, patience 431998, iter 292499, train error 23.806667 %, valid error 24.460000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 66, minibatch 4500/4500, patience 431998, iter 296999, train error 23.481333 %, valid error 23.972000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 67, minibatch 4500/4500, patience 431998, iter 301499, train error 23.415111 %, valid error 23.812000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 68, minibatch 4500/4500, patience 431998, iter 305999, train error 23.670667 %, valid error 23.876000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 69, minibatch 4500/4500, patience 431998, iter 310499, train error 22.782667 %, valid error 22.920000 %, best valid error 23.428000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 70, minibatch 4500/4500, patience 620998, iter 314999, train error 22.612000 %, valid error 23.232000 %, best valid error 22.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 71, minibatch 4500/4500, patience 620998, iter 319499, train error 22.565333 %, valid error 23.300000 %, best valid error 22.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 72, minibatch 4500/4500, patience 620998, iter 323999, train error 22.414222 %, valid error 22.652000 %, best valid error 22.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 73, minibatch 4500/4500, patience 647998, iter 328499, train error 23.954667 %, valid error 23.900000 %, best valid error 22.652000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 74, minibatch 4500/4500, patience 647998, iter 332999, train error 22.468889 %, valid error 22.644000 %, best valid error 22.652000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 75, minibatch 4500/4500, patience 647998, iter 337499, train error 22.578222 %, valid error 22.812000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 76, minibatch 4500/4500, patience 647998, iter 341999, train error 22.537333 %, valid error 23.048000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 77, minibatch 4500/4500, patience 647998, iter 346499, train error 22.557778 %, valid error 23.056000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 78, minibatch 4500/4500, patience 647998, iter 350999, train error 22.380000 %, valid error 22.916000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 79, minibatch 4500/4500, patience 647998, iter 355499, train error 22.815556 %, valid error 23.096000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 80, minibatch 4500/4500, patience 647998, iter 359999, train error 22.892444 %, valid error 23.468000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 81, minibatch 4500/4500, patience 647998, iter 364499, train error 23.108444 %, valid error 23.532000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 82, minibatch 4500/4500, patience 647998, iter 368999, train error 22.562222 %, valid error 23.060000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 83, minibatch 4500/4500, patience 647998, iter 373499, train error 22.519556 %, valid error 22.940000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 84, minibatch 4500/4500, patience 647998, iter 377999, train error 22.851111 %, valid error 23.440000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 85, minibatch 4500/4500, patience 647998, iter 382499, train error 22.662222 %, valid error 23.192000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 86, minibatch 4500/4500, patience 647998, iter 386999, train error 22.626222 %, valid error 23.024000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 87, minibatch 4500/4500, patience 647998, iter 391499, train error 22.706667 %, valid error 22.708000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 88, minibatch 4500/4500, patience 647998, iter 395999, train error 22.616444 %, valid error 23.156000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 89, minibatch 4500/4500, patience 647998, iter 400499, train error 22.166222 %, valid error 22.972000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 90, minibatch 4500/4500, patience 647998, iter 404999, train error 22.419556 %, valid error 22.660000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 91, minibatch 4500/4500, patience 647998, iter 409499, train error 22.834667 %, valid error 23.580000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 92, minibatch 4500/4500, patience 647998, iter 413999, train error 23.221778 %, valid error 23.852000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 93, minibatch 4500/4500, patience 647998, iter 418499, train error 22.561333 %, valid error 22.724000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 94, minibatch 4500/4500, patience 647998, iter 422999, train error 21.910222 %, valid error 22.224000 %, best valid error 22.644000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 95, minibatch 4500/4500, patience 845998, iter 427499, train error 22.281778 %, valid error 23.036000 %, best valid error 22.224000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 96, minibatch 4500/4500, patience 845998, iter 431999, train error 21.702667 %, valid error 22.208000 %, best valid error 22.224000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 97, minibatch 4500/4500, patience 845998, iter 436499, train error 22.943556 %, valid error 23.288000 %, best valid error 22.208000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 98, minibatch 4500/4500, patience 845998, iter 440999, train error 22.004889 %, valid error 22.120000 %, best valid error 22.208000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 99, minibatch 4500/4500, patience 845998, iter 445499, train error 22.149778 %, valid error 22.668000 %, best valid error 22.120000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 100, minibatch 4500/4500, patience 845998, iter 449999, train error 21.985778 %, valid error 22.076000 %, best valid error 22.120000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 101, minibatch 4500/4500, patience 845998, iter 454499, train error 22.768889 %, valid error 23.172000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 102, minibatch 4500/4500, patience 845998, iter 458999, train error 22.740444 %, valid error 23.216000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 103, minibatch 4500/4500, patience 845998, iter 463499, train error 21.575556 %, valid error 22.216000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 104, minibatch 4500/4500, patience 845998, iter 467999, train error 22.925778 %, valid error 23.640000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 105, minibatch 4500/4500, patience 845998, iter 472499, train error 22.701778 %, valid error 23.480000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 106, minibatch 4500/4500, patience 845998, iter 476999, train error 22.087111 %, valid error 22.784000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 107, minibatch 4500/4500, patience 845998, iter 481499, train error 22.583556 %, valid error 22.464000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 108, minibatch 4500/4500, patience 845998, iter 485999, train error 22.029778 %, valid error 22.420000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 109, minibatch 4500/4500, patience 845998, iter 490499, train error 22.118222 %, valid error 22.460000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 110, minibatch 4500/4500, patience 845998, iter 494999, train error 21.864889 %, valid error 22.124000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 111, minibatch 4500/4500, patience 845998, iter 499499, train error 21.471556 %, valid error 21.968000 %, best valid error 22.076000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 112, minibatch 4500/4500, patience 845998, iter 503999, train error 21.353778 %, valid error 21.900000 %, best valid error 21.968000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 113, minibatch 4500/4500, patience 845998, iter 508499, train error 21.816889 %, valid error 22.288000 %, best valid error 21.900000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 114, minibatch 4500/4500, patience 845998, iter 512999, train error 22.028000 %, valid error 22.592000 %, best valid error 21.900000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 115, minibatch 4500/4500, patience 845998, iter 517499, train error 21.894222 %, valid error 22.284000 %, best valid error 21.900000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 116, minibatch 4500/4500, patience 845998, iter 521999, train error 22.760000 %, valid error 23.084000 %, best valid error 21.900000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 117, minibatch 4500/4500, patience 845998, iter 526499, train error 22.135111 %, valid error 22.744000 %, best valid error 21.900000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 118, minibatch 4500/4500, patience 845998, iter 530999, train error 21.283556 %, valid error 21.620000 %, best valid error 21.900000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 119, minibatch 4500/4500, patience 1061998, iter 535499, train error 21.597778 %, valid error 21.788000 %, best valid error 21.620000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 120, minibatch 4500/4500, patience 1061998, iter 539999, train error 22.032889 %, valid error 22.492000 %, best valid error 21.620000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 121, minibatch 4500/4500, patience 1061998, iter 544499, train error 22.247556 %, valid error 22.376000 %, best valid error 21.620000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 122, minibatch 4500/4500, patience 1061998, iter 548999, train error 21.303111 %, valid error 21.812000 %, best valid error 21.620000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 123, minibatch 4500/4500, patience 1061998, iter 553499, train error 22.107111 %, valid error 22.376000 %, best valid error 21.620000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 124, minibatch 4500/4500, patience 1061998, iter 557999, train error 22.348889 %, valid error 22.612000 %, best valid error 21.620000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 125, minibatch 4500/4500, patience 1061998, iter 562499, train error 21.328889 %, valid error 21.532000 %, best valid error 21.620000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 126, minibatch 4500/4500, patience 1061998, iter 566999, train error 21.421778 %, valid error 22.144000 %, best valid error 21.532000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 127, minibatch 4500/4500, patience 1061998, iter 571499, train error 21.596889 %, valid error 21.964000 %, best valid error 21.532000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 128, minibatch 4500/4500, patience 1061998, iter 575999, train error 21.121778 %, valid error 21.572000 %, best valid error 21.532000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 129, minibatch 4500/4500, patience 1061998, iter 580499, train error 22.169778 %, valid error 22.244000 %, best valid error 21.532000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 130, minibatch 4500/4500, patience 1061998, iter 584999, train error 21.770222 %, valid error 21.952000 %, best valid error 21.532000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 131, minibatch 4500/4500, patience 1061998, iter 589499, train error 21.287111 %, valid error 21.416000 %, best valid error 21.532000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 132, minibatch 4500/4500, patience 1178998, iter 593999, train error 21.450667 %, valid error 21.808000 %, best valid error 21.416000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 133, minibatch 4500/4500, patience 1178998, iter 598499, train error 21.487556 %, valid error 21.944000 %, best valid error 21.416000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 134, minibatch 4500/4500, patience 1178998, iter 602999, train error 20.884889 %, valid error 21.372000 %, best valid error 21.416000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 135, minibatch 4500/4500, patience 1178998, iter 607499, train error 20.648889 %, valid error 20.920000 %, best valid error 21.372000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 136, minibatch 4500/4500, patience 1214998, iter 611999, train error 21.366222 %, valid error 21.680000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 137, minibatch 4500/4500, patience 1214998, iter 616499, train error 21.163111 %, valid error 21.572000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 138, minibatch 4500/4500, patience 1214998, iter 620999, train error 20.984000 %, valid error 21.192000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 139, minibatch 4500/4500, patience 1214998, iter 625499, train error 21.001778 %, valid error 21.480000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 140, minibatch 4500/4500, patience 1214998, iter 629999, train error 21.988889 %, valid error 22.204000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 141, minibatch 4500/4500, patience 1214998, iter 634499, train error 20.853778 %, valid error 21.436000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 142, minibatch 4500/4500, patience 1214998, iter 638999, train error 22.361333 %, valid error 22.748000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 143, minibatch 4500/4500, patience 1214998, iter 643499, train error 21.628889 %, valid error 22.268000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 144, minibatch 4500/4500, patience 1214998, iter 647999, train error 21.379556 %, valid error 21.820000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 145, minibatch 4500/4500, patience 1214998, iter 652499, train error 21.396000 %, valid error 21.604000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 146, minibatch 4500/4500, patience 1214998, iter 656999, train error 21.522667 %, valid error 22.100000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 147, minibatch 4500/4500, patience 1214998, iter 661499, train error 22.274222 %, valid error 22.604000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 148, minibatch 4500/4500, patience 1214998, iter 665999, train error 22.139556 %, valid error 22.520000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 149, minibatch 4500/4500, patience 1214998, iter 670499, train error 21.863556 %, valid error 22.356000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 150, minibatch 4500/4500, patience 1214998, iter 674999, train error 21.498667 %, valid error 22.060000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 151, minibatch 4500/4500, patience 1214998, iter 679499, train error 21.348444 %, valid error 21.868000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 152, minibatch 4500/4500, patience 1214998, iter 683999, train error 21.556444 %, valid error 21.820000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 153, minibatch 4500/4500, patience 1214998, iter 688499, train error 21.162222 %, valid error 21.620000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 154, minibatch 4500/4500, patience 1214998, iter 692999, train error 21.238667 %, valid error 21.820000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 155, minibatch 4500/4500, patience 1214998, iter 697499, train error 22.253778 %, valid error 22.708000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 156, minibatch 4500/4500, patience 1214998, iter 701999, train error 21.696000 %, valid error 22.528000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 157, minibatch 4500/4500, patience 1214998, iter 706499, train error 21.566667 %, valid error 21.840000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 158, minibatch 4500/4500, patience 1214998, iter 710999, train error 21.404444 %, valid error 21.560000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 159, minibatch 4500/4500, patience 1214998, iter 715499, train error 22.127111 %, valid error 22.476000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 160, minibatch 4500/4500, patience 1214998, iter 719999, train error 21.195111 %, valid error 21.616000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 161, minibatch 4500/4500, patience 1214998, iter 724499, train error 21.642222 %, valid error 21.752000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 162, minibatch 4500/4500, patience 1214998, iter 728999, train error 21.254222 %, valid error 21.860000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 163, minibatch 4500/4500, patience 1214998, iter 733499, train error 21.998667 %, valid error 22.740000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 164, minibatch 4500/4500, patience 1214998, iter 737999, train error 21.104000 %, valid error 21.644000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 165, minibatch 4500/4500, patience 1214998, iter 742499, train error 22.094667 %, valid error 22.720000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 166, minibatch 4500/4500, patience 1214998, iter 746999, train error 21.747111 %, valid error 22.480000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 167, minibatch 4500/4500, patience 1214998, iter 751499, train error 21.750222 %, valid error 22.264000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 168, minibatch 4500/4500, patience 1214998, iter 755999, train error 21.864889 %, valid error 22.228000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 169, minibatch 4500/4500, patience 1214998, iter 760499, train error 21.597778 %, valid error 22.244000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 170, minibatch 4500/4500, patience 1214998, iter 764999, train error 20.769333 %, valid error 21.120000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 171, minibatch 4500/4500, patience 1214998, iter 769499, train error 21.483111 %, valid error 21.816000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 172, minibatch 4500/4500, patience 1214998, iter 773999, train error 20.811556 %, valid error 21.536000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 173, minibatch 4500/4500, patience 1214998, iter 778499, train error 21.164000 %, valid error 21.632000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 174, minibatch 4500/4500, patience 1214998, iter 782999, train error 20.790667 %, valid error 21.140000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 175, minibatch 4500/4500, patience 1214998, iter 787499, train error 21.670222 %, valid error 22.164000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 176, minibatch 4500/4500, patience 1214998, iter 791999, train error 20.926667 %, valid error 21.556000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 177, minibatch 4500/4500, patience 1214998, iter 796499, train error 20.833778 %, valid error 21.328000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 178, minibatch 4500/4500, patience 1214998, iter 800999, train error 20.927111 %, valid error 21.500000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 179, minibatch 4500/4500, patience 1214998, iter 805499, train error 20.980444 %, valid error 21.276000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 180, minibatch 4500/4500, patience 1214998, iter 809999, train error 20.517778 %, valid error 21.156000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 181, minibatch 4500/4500, patience 1214998, iter 814499, train error 21.288889 %, valid error 21.972000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 182, minibatch 4500/4500, patience 1214998, iter 818999, train error 20.997778 %, valid error 21.668000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 183, minibatch 4500/4500, patience 1214998, iter 823499, train error 21.279556 %, valid error 21.968000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 184, minibatch 4500/4500, patience 1214998, iter 827999, train error 20.819556 %, valid error 21.224000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 185, minibatch 4500/4500, patience 1214998, iter 832499, train error 21.064444 %, valid error 21.864000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 186, minibatch 4500/4500, patience 1214998, iter 836999, train error 20.836889 %, valid error 21.228000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 187, minibatch 4500/4500, patience 1214998, iter 841499, train error 20.622667 %, valid error 20.748000 %, best valid error 20.920000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 188, minibatch 4500/4500, patience 1682998, iter 845999, train error 22.124000 %, valid error 22.500000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 189, minibatch 4500/4500, patience 1682998, iter 850499, train error 21.217333 %, valid error 21.872000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 190, minibatch 4500/4500, patience 1682998, iter 854999, train error 21.000444 %, valid error 21.304000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 191, minibatch 4500/4500, patience 1682998, iter 859499, train error 22.574222 %, valid error 23.032000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 192, minibatch 4500/4500, patience 1682998, iter 863999, train error 21.516000 %, valid error 21.972000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 193, minibatch 4500/4500, patience 1682998, iter 868499, train error 22.566667 %, valid error 22.724000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 194, minibatch 4500/4500, patience 1682998, iter 872999, train error 22.327111 %, valid error 22.708000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 195, minibatch 4500/4500, patience 1682998, iter 877499, train error 22.184889 %, valid error 22.824000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 196, minibatch 4500/4500, patience 1682998, iter 881999, train error 21.488889 %, valid error 22.048000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 197, minibatch 4500/4500, patience 1682998, iter 886499, train error 21.474667 %, valid error 22.020000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 198, minibatch 4500/4500, patience 1682998, iter 890999, train error 21.212889 %, valid error 21.668000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 199, minibatch 4500/4500, patience 1682998, iter 895499, train error 21.494222 %, valid error 21.976000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 200, minibatch 4500/4500, patience 1682998, iter 899999, train error 21.520889 %, valid error 22.124000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 201, minibatch 4500/4500, patience 1682998, iter 904499, train error 21.223556 %, valid error 22.032000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 202, minibatch 4500/4500, patience 1682998, iter 908999, train error 21.789333 %, valid error 22.076000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 203, minibatch 4500/4500, patience 1682998, iter 913499, train error 21.119111 %, valid error 21.580000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 204, minibatch 4500/4500, patience 1682998, iter 917999, train error 21.770222 %, valid error 22.272000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 205, minibatch 4500/4500, patience 1682998, iter 922499, train error 21.029778 %, valid error 21.484000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 206, minibatch 4500/4500, patience 1682998, iter 926999, train error 20.894222 %, valid error 21.548000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 207, minibatch 4500/4500, patience 1682998, iter 931499, train error 22.290667 %, valid error 23.032000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 208, minibatch 4500/4500, patience 1682998, iter 935999, train error 20.980000 %, valid error 21.560000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 209, minibatch 4500/4500, patience 1682998, iter 940499, train error 21.410667 %, valid error 22.428000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 210, minibatch 4500/4500, patience 1682998, iter 944999, train error 21.632000 %, valid error 22.152000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 211, minibatch 4500/4500, patience 1682998, iter 949499, train error 22.989778 %, valid error 23.396000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 212, minibatch 4500/4500, patience 1682998, iter 953999, train error 21.188889 %, valid error 21.472000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 213, minibatch 4500/4500, patience 1682998, iter 958499, train error 21.035556 %, valid error 21.296000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 214, minibatch 4500/4500, patience 1682998, iter 962999, train error 21.151111 %, valid error 21.732000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 215, minibatch 4500/4500, patience 1682998, iter 967499, train error 21.406222 %, valid error 22.100000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 216, minibatch 4500/4500, patience 1682998, iter 971999, train error 22.003556 %, valid error 22.548000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 217, minibatch 4500/4500, patience 1682998, iter 976499, train error 21.314667 %, valid error 21.876000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 218, minibatch 4500/4500, patience 1682998, iter 980999, train error 22.138222 %, valid error 22.364000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 219, minibatch 4500/4500, patience 1682998, iter 985499, train error 20.684444 %, valid error 21.276000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 220, minibatch 4500/4500, patience 1682998, iter 989999, train error 22.304000 %, valid error 22.600000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 221, minibatch 4500/4500, patience 1682998, iter 994499, train error 22.002667 %, valid error 22.264000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "epoch 222, minibatch 4500/4500, patience 1682998, iter 998999, train error 21.986222 %, valid error 22.556000 %, best valid error 20.748000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-180-7cf0cc67902d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorsValidation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_mlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL1_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL2_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-177-d4ddc40b0374>\u001b[0m in \u001b[0;36mtest_mlp\u001b[1;34m(learning_rate, L1_reg, L2_reg, n_epochs, batch_size, n_hidden)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mminibatch_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mminibatch_avg_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;31m# iteration number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0miter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_train_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mminibatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the learning errors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "fig = plt.figure()\n",
      "fig.suptitle('Logistic regression learning curves', fontsize=14, fontweight='bold')\n",
      "ax = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "ax.set_xlabel('number of epochs')\n",
      "ax.set_ylabel('errors')\n",
      "\n",
      "ax.plot(range(epoch), errorsTrain[:epoch] * 100, 'b-')\n",
      "ax.plot(range(epoch), errorsValidation[:epoch] * 100, 'r-')\n",
      "\n",
      "ax.axis([0, epoch, 0, 100])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculate validation scores and sort them in increasing order of the scores:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scoresValidation = net.activateOnDataset(dsValidation)[:, 1]\n",
      "#print scoresValidation.transpose()\n",
      "\n",
      "tIIs = scoresValidation.argsort()\n",
      "#print tIIs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We define the Approximate Median Significance:\n",
      "\n",
      "\\begin{equation*}\n",
      "\\text{AMS} = \\sqrt{ 2 \\left( (s + b + 10) \\ln \\left( 1 + \\frac{s}{b +\n",
      "    10} \\right) - s \\right) }\n",
      "\\end{equation*}\n",
      "\n",
      "where <code>s</code> and <code>b</code> are the sum of signal and background weights, respectively, in the selection region."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AMS(s,b):\n",
      "    assert s >= 0\n",
      "    assert b >= 0\n",
      "    bReg = 10.\n",
      "    return math.sqrt(2 * ((s + b + bReg) * math.log(1 + s / (b + bReg)) - s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Weights have to be normalized to the same sum as in the full set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wFactor = 1.* numPoints / numPointsValidation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initializing $s$ and $b$ to the full sum of weights, we start by having all points in the selection region. <code>amss</code> will contain AMSs after each point moved out of the selection region in the sorted validation set. <code>amsMax</code> will contain the best validation AMS, and <code>threshold</code> will be the smallest score among the selected points. We will do <code>len(tIIs)</code> iterations, which means that <code>amss[-1]</code> is the AMS when only the point with the highest score is selected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = np.sum(weightsValidation[sSelectorValidation])\n",
      "b = np.sum(weightsValidation[bSelectorValidation])\n",
      "amss = np.empty([len(tIIs)])\n",
      "amsMax = 0\n",
      "threshold = 0.0\n",
      "for tI in range(len(tIIs)):\n",
      "    # don't forget to renormalize the weights to the same sum \n",
      "    # as in the complete training set\n",
      "    amss[tI] = AMS(max(0,s * wFactor),max(0,b * wFactor))\n",
      "    # careful with small regions, they fluctuate a lot\n",
      "    if tI < 0.9 * len(tIIs) and amss[tI] > amsMax:\n",
      "        amsMax = amss[tI]\n",
      "        threshold = scoresValidation[tIIs[tI]]\n",
      "        #print tI,threshold\n",
      "    if sSelectorValidation[tIIs[tI]]:\n",
      "        s -= weightsValidation[tIIs[tI]]\n",
      "    else:\n",
      "        b -= weightsValidation[tIIs[tI]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the AMS vs the rank."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "fig.suptitle('AMS curves', fontsize=14, fontweight='bold')\n",
      "vsRank = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "vsRank.set_xlabel('rank')\n",
      "vsRank.set_ylabel('AMS')\n",
      "\n",
      "vsRank.plot(amss,'b-')\n",
      "\n",
      "vsRank.axis([0,len(amss), 0, 4])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the AMS vs the score."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "fig.suptitle('MultiBoost AMS curves', fontsize=14, fontweight='bold')\n",
      "vsScore = fig.add_subplot(111)\n",
      "fig.subplots_adjust(top=0.85)\n",
      "\n",
      "vsScore.set_xlabel('score')\n",
      "vsScore.set_ylabel('AMS')\n",
      "\n",
      "vsScore.plot(scoresValidation[tIIs],amss,'b-')\n",
      "\n",
      "vsScore.axis([scoresValidation[tIIs[0]], scoresValidation[tIIs[-1]] , 0, 4])\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Constructing the submission file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allTest = list(csv.reader(open(\"../data/test.csv\",\"rb\"), delimiter=','))\n",
      "\n",
      "xsTest = normalize(allTest[1:], 1, 31)\n",
      "(numTestPoints, numTestFeatures) = xsTest.shape\n",
      "\n",
      "print numTestPoints, numFeatures, numTestFeatures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "550000 30 30\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testIds = np.array([int(row[0]) for row in allTest[1:]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testScores = np.zeros(numTestPoints)\n",
      "\n",
      "for i in range(numTestPoints):\n",
      "    testScores[i] = net.activate(xsTest[i])[1]\n",
      "\n",
      "#print testScores.transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computing the rank order."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testInversePermutation = testScores.argsort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testPermutation = list(testInversePermutation)\n",
      "for tI,tII in zip(range(len(testInversePermutation)), testInversePermutation):\n",
      "    testPermutation[tII] = tI"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Computing the submission file with columns EventId, RankOrder, and Class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = np.array([[str(testIds[tI]),str(testPermutation[tI]+1),\n",
      "                       's' if testScores[tI] >= threshold else 'b'] \n",
      "            for tI in range(len(testIds))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = np.append([['EventId','RankOrder','Class']], submission, axis=0)\n",
      "\n",
      "np.savetxt(\"submission.csv\",submission,fmt='%s',delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}